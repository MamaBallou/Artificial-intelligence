{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation d'algorithmes de régression linéaire\n",
    "\n",
    "$\\hat{y}_i = w . X_i \\Rightarrow \\hat{y} = X_w = XX^+y = Hy$\n",
    "\n",
    "## Exemple\n",
    "\n",
    "Supposons que l'on a le dataset suivant :\n",
    "$$D = \\{(1,1),(2,2),(3,2)\\}$$\n",
    "\n",
    "On a donc le système :\n",
    "$$ \\left\\{ \\begin{aligned}\n",
    "w_0 + w_1 &= 1 \\\\\n",
    "w_0 + 2w_1 &= 2 \\\\\n",
    "w_0 + 3w_1 &= 2\n",
    "\\end{aligned} \\right.$$\n",
    "\n",
    "Soit sous forme matricielle :\n",
    "$$ \\left[ \\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "1 & 2 \\\\\n",
    "1 & 3\n",
    "\\end{array} \\right] \\left[ \\begin{array}{c}\n",
    "w_0 \\\\\n",
    "w_1\n",
    "\\end{array} \\right] = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "2\n",
    "\\end{array} \\right] $$\n",
    "> Il n'existe pas de ligne passant pas tous ces points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On résoud l'équation Normale :\n",
    "$$X^T Xw = X^T y$$\n",
    "\n",
    "$X^T X = \\left[ \\begin{array}{ccc}\n",
    "1 & 1 & 1 \\\\\n",
    "1 & 2 & 3\n",
    "\\end{array} \\right] \\left[ \\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "1 & 2 \\\\\n",
    "1 & 3\n",
    "\\end{array} \\right] = \\left[ \\begin{array}{cc}\n",
    "3 & 6 \\\\\n",
    "6 & 14\n",
    "\\end{array} \\right]$\n",
    "\n",
    "$(X^T X)^{-1} = \\frac{\\text{Com}(A)}{\\det(X^T X)} = \\frac{1}{6} \\left[ \\begin{array}{cc}\n",
    "14 & -6 \\\\\n",
    "-6 & 3\n",
    "\\end{array} \\right]$\n",
    "\n",
    "$(X^T X)^{-1}y = \\frac{1}{6} \\left[ \\begin{array}{cc}\n",
    "14 & -6 \\\\\n",
    "-6 & 3\n",
    "\\end{array} \\right] \\left[ \\begin{array}{c}\n",
    "5 \\\\\n",
    "11\n",
    "\\end{array} \\right] = \\frac{1}{6} \\left[ \\begin{array}{c}\n",
    "4 \\\\\n",
    "3\n",
    "\\end{array} \\right] = \\left[ \\begin{array}{c}\n",
    "\\frac{2}{3} \\\\\n",
    "\\frac{1}{2}\n",
    "\\end{array} \\right]$\n",
    "\n",
    "Donc la meilleure droite de régression est :\n",
    "$$y = \\frac{2}{3} + \\frac{1}{2}x$$\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"Droite_regression_exemple.png\" width=30%/></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer le vecteur d'erreur :\n",
    "$$\\hat{w} = \\left[ \\begin{array}{c}\n",
    "\\frac{2}{3} \\\\\n",
    "\\frac{1}{2}\n",
    "\\end{array} \\right],\\ X = \\left[ \\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "1 & 2 \\\\\n",
    "1 & 3\n",
    "\\end{array} \\right],\\ y = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "2\n",
    "\\end{array} \\right]$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projections :\n",
    "$$P = X \\hat{w} = \\left[ \\begin{array}{cc}\n",
    "1 & 1 \\\\\n",
    "1 & 2 \\\\\n",
    "1 & 3\n",
    "\\end{array} \\right] \\left[ \\begin{array}{c}\n",
    "\\frac{2}{3} \\\\\n",
    "\\frac{1}{2}\n",
    "\\end{array} \\right] = \\left[ \\begin{array}{c}\n",
    "\\frac{7}{6} \\\\\n",
    "\\frac{5}{3} \\\\\n",
    "\\frac{13}{6}\n",
    "\\end{array} \\right]$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$e = y - \\hat{y} = y - X \\hat{w} = \\left[ \\begin{array}{c}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "2\n",
    "\\end{array} \\right] - \\left[ \\begin{array}{c}\n",
    "\\frac{7}{6} \\\\\n",
    "\\frac{5}{3} \\\\\n",
    "\\frac{13}{6}\n",
    "\\end{array} \\right] = \\left[ \\begin{array}{c}\n",
    "- \\frac{1}{6} \\\\\n",
    "\\frac{2}{3} \\\\\n",
    "- \\frac{1}{6}\n",
    "\\end{array} \\right]$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"droite_represantation_erreur.png\" width=30%/></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le problème avec les droites polynomiales\n",
    "## Comment choisir les *hyperparamètres* ?\n",
    "### K-Fold Cross Validation : Pseudo-code\n",
    "\n",
    "**K-Fold cross validation**\n",
    "* pour chaque *hyperparamètre* :\n",
    "    * pour $i=1$:$k$ :\n",
    "        * entrainer le model sur tous les points sauf les $i$-ème\n",
    "        * évaluer le model sur les $i$-ème points\n",
    "* choisir l'*hyperparamètre* avec la meilleure moyenne de performance\n",
    "\n",
    "* $k$ lui même est un *hyperparamètre* mais il est souvent fixé à 4 ou 10.\n",
    "\n",
    "## Sensibilité du model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regularisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\underbrace{ \\underset{\\omega} \\min || X\\omega - y ||_2^2 }_{\\substack{\\text{Trained error}}} + \\underbrace{\\lambda || \\omega ||_2^2}_{\\substack{\\text{Keep weights small}}} \\\\\n",
    "    \\lambda\n",
    "$ est un *hyperparamètre*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression logistique"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour estimer la propabilité d'appartenance à une classe. Donc des valeurs numériques entre 0 et 1.\n",
    "\n",
    "Généralement utilisé pour la classification binaire.\n",
    "\n",
    "Appartient au modèles discriminatifs.\n",
    "\n",
    "$\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"regrassion_logistique.png\" width=30%/></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence avec :\n",
    "* Une régression linéaire $\\omega^T X$\n",
    "* Le résultat est transformé en probabilité par la fonction $\\sigma$. Le *Sigmoid*\n",
    "\n",
    "*Sigmoid* est utilisé pour estimé une distribution de probabilité. Une distribution de Bernoulli.\n",
    "$$P(\\hat{Y} = 1|x,\\omega) = s(\\omega^T x),\\ P(\\hat{Y} = 0|x,\\omega) = 1 - s(\\omega^T x)$$\n",
    "Ici $s$ est la fonction *Sigmoid*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut donc maximiser la vraisemblance de nos données noté $X$ :\n",
    "$$\\begin{aligned}\n",
    "\\hat{y} &= \\underset{k}\\max P(\\hat{Y} = k|x,\\omega)\n",
    "&= \\left\\{ \\begin{array}{c} 1 \\text{ si } s(\\omega^T x) \\geqq 0.5 \\\\\n",
    " 0 \\text{ sinon} \\end{array} \\right.\n",
    "\\end{aligned}$$\n",
    "\n",
    "Une notation équivalente est :\n",
    "$$\\hat{y} = \\left\\{ \\begin{array}{c} 1 \\text{ si } \\omega^T x > 0 \\\\\n",
    " 0 \\text{ sinon} \\end{array} \\right.$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résumé régression et fonction perte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions régresssion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linéaire : $h(x; \\omega, \\alpha) = \\omega . x + \\alpha$\n",
    "* Polynomiale\n",
    "    * Équivalent à la régression linéaire sous forme de polynôme\n",
    "* Logistique : h(x; \\omega, \\alpha) = $s(\\omega . x + \\alpha), \\\\ s(\\gamma) = \\frac{1}{1 + e^{- \\gamma}} $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foncitons d'erreur"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squared Error : $L(z,y) = (z - y)^2$\n",
    "* Absolute Error : $L(z,y) = |z - y|$\n",
    "* Logistique aka Cross Entropy : $L(z,y) = -y \\log(z) - (1 - y) \\log(1 - z)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE : Mean Absolute Error c'est OLS\n",
    "\n",
    "RMSE : Root Mean Squared Error c'est Ridge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La somme des moindres carrés est très sensible aux outliers (données aberrantes). Donc pas d'OLS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\"><img src=\"tendance_droite.png\" width=40%/></div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
