{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme supervisé et non supervisé\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'**apprentissage supervisé** est utilisé lorsque l'on dispose d'un **ensemble de données étiquetées**, c'est-à-dire que chaque exemple de données est associé à une étiquette de classe ou à une **valeur de sortie connue**. L'objectif de l'apprentissage supervisé est de construire un modèle qui peut prédire la sortie correspondante à une nouvelle entrée. Les algorithmes supervisés incluent la **régression linéaire**, les **arbres de décision**, les **réseaux de neurones**, le **SVM**, etc.\n",
    "\n",
    "- L'**apprentissage non supervisé**, en revanche, est utilisé lorsqu'on dispose d'un ensemble de **données non étiquetées**, c'est-à-dire que les exemples de données ne sont pas associés à une étiquette de classe ou à une valeur de sortie connue. L'objectif de l'apprentissage non supervisé est de découvrir des structures ou des modèles cachés dans les données, tels que des groupes similaires ou des tendances cachées. Les algorithmes non supervisés incluent la classification non supervisée, la **segmentation de cluster**, l'**analyse en composantes principales** (PCA), l'**analyse factorielle**, etc.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctionnement de la régression linéaire\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Collecte de données** : Collecter des données sur les variables d'entrée et de sortie que l'on souhaite modéliser.\n",
    "\n",
    "1. **Exploration des données** : Examiner les données pour comprendre la relation entre les variables d'entrée et de sortie. Cela peut inclure la visualisation de graphiques pour déterminer s'il existe une relation linéaire entre les variables.\n",
    "\n",
    "1. **Sélection de la fonction de coût** : Déterminer la fonction de coût à utiliser pour évaluer la qualité de l'ajustement de la droite de régression aux données. La fonction de coût la plus courante est la somme des carrés des écarts (ou SSE).\n",
    "\n",
    "1. **Détermination des coefficients de la droite de régression** : Trouver les coefficients de pente et d'ordonnée à l'origine qui minimisent la fonction de coût.\n",
    "\n",
    "1. **Évaluation du modèle** : Évaluer la qualité de l'ajustement de la droite de régression aux données. Cela peut inclure l'examen des résidus (les écarts entre les valeurs prédites et les valeurs réelles) et l'utilisation de mesures de performance telles que le coefficient de détermination (ou R2) pour évaluer la précision du modèle.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cas d'usage de la régression linéaire par rapport à un besoin\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour maximiser ou minimiser un coût, pour prédire une valeur, pour trouver une relation entre deux variables, pour trouver une tendance, pour trouver une corrélation, pour trouver une relation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cf [Work Shop 2](./WS2/WS_2_2_-_Pipeline_Machine_Learning.ipynb)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculer la régression linéaire sur un jeu de données\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyser les résultats obtenus par la régression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "# On applique le full_pipeline sur quelques instances :\n",
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "# Et on effectue la prédiction :\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
    "```\n",
    "\n",
    "On compare aux valeurs réelles :\n",
    "\n",
    "```py\n",
    "print(\"Labels:\", list(some_labels)) # vraies valeurs\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Améliorer le modèle de régression en fonction des résultats obtenus (Amélioration continue)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Collecter plus de données** : Si vous disposez d'un nombre limité de données, vous pouvez essayer d'en collecter davantage pour améliorer la précision de votre modèle. Plus vous avez de données, plus votre modèle peut apprendre de motifs et de tendances, ce qui peut améliorer sa capacité à faire des prédictions précises.\n",
    "\n",
    "- **Explorer de nouvelles variables** : Vous pouvez examiner les variables que vous avez utilisées pour votre modèle et envisager d'en ajouter de nouvelles qui pourraient contribuer à améliorer la précision des prédictions. Par exemple, vous pouvez explorer des variables qui ont été négligées lors de la première phase de modélisation.\n",
    "\n",
    "- **Éliminer les variables non pertinentes** : En revanche, il peut arriver que certaines variables n'apportent pas grand-chose à votre modèle et peuvent même avoir un effet négatif sur la précision des prédictions. Vous pouvez donc essayer d'éliminer les variables qui n'ont pas d'impact significatif sur le résultat final.\n",
    "\n",
    "- **Modifier les paramètres du modèle** : Vous pouvez ajuster les paramètres de votre modèle pour améliorer sa performance. Par exemple, en utilisant une fonction de coût différente, ou en modifiant les hyperparamètres tels que la profondeur du modèle.\n",
    "\n",
    "- **Utiliser un algorithme différent** : Si vous avez essayé différentes approches et que votre modèle ne donne pas de bons résultats, vous pouvez essayer de changer d'algorithme. Il existe de nombreux algorithmes de régression différents, chacun ayant des avantages et des inconvénients. Il peut donc être utile d'explorer d'autres options pour trouver celle qui convient le mieux à vos données et à votre objectif.\n",
    "\n",
    "- **Évaluer les performances du modèle** : Enfin, il est important de continuer à évaluer les performances de votre modèle. Cela peut vous aider à identifier les zones où il y a des problèmes et à comprendre les raisons de ces problèmes. Vous pouvez également utiliser des techniques d'ensemble pour améliorer la précision de votre modèle. Par exemple, en combinant plusieurs modèles de régression différents pour obtenir une prédiction plus précise.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mesurer les résultats obtenus (identifier la métrique d'évaluation adaptée : RMSE, MSE, MAE, Risge, Lasso)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **RMSE** (Root Mean Squared Error) : il s'agit de la racine carrée de la moyenne des carrés des différences entre les prédictions et les valeurs réelles. Cette métrique est souvent utilisée pour évaluer la précision des modèles de régression. Elle donne une idée de la distance entre les prédictions et les vraies valeurs, en prenant en compte les erreurs positives et négatives. Plus la valeur de RMSE est faible, meilleure est la performance du modèle.$\\text{RMSE}(X,h)=\\sqrt{\\frac{1}{m}\\sum_{i=1}^{m}{(h(x^{(i)})-y^{(i)})^2}}$\n",
    "<p align=\"center\">\n",
    "  <img src=\"./RMSE.jpg\" style=\"max-width:50%\"/>\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **MSE** (Mean Squared Error) : il s'agit de la moyenne des carrés des différences entre les prédictions et les valeurs réelles. Tout comme RMSE, cette métrique est souvent utilisée pour évaluer la précision des modèles de régression. Cependant, elle peut être plus sensible aux valeurs aberrantes que RMSE, car elle ne prend pas en compte la racine carrée.\n",
    "<p align=\"center\">\n",
    "  <img src=\"./MSE.webp\" style=\"max-width:50%\"/>\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **MAE** (Mean Absolute Error) : il s'agit de la moyenne des différences absolues entre les prédictions et les valeurs réelles. Cette métrique est également utilisée pour évaluer la précision des modèles de régression. Elle donne une idée de la distance moyenne entre les prédictions et les vraies valeurs. Elle est moins sensible aux valeurs aberrantes que MSE et RMSE, car elle ne prend pas en compte les carrés. $\\text{MAE}(X,h)=\\frac{1}{m}\\sum_{i=1}^{m}{\\lvert h(x^{(i)})-y^{(i)})\\rvert}$\n",
    "<p align=\"center\">\n",
    "  <img src=\"./MAE.jpeg\" style=\"max-width:50%\"/>\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **R2** (Coefficient de détermination) : il s'agit d'une mesure de la proportion de variance expliquée par le modèle. Plus la valeur de R2 est proche de 1, meilleure est la performance du modèle. Cette métrique est souvent utilisée pour évaluer la qualité des modèles de régression. $\\text{R2} = 1 -\\frac{\\text{SS}_\\text{res}}{\\text{SS}_\\text{tot}}$\n",
    "\n",
    "|![](./SStot.png)|![](./SSres.png)|\n",
    "|:-:|:-:|\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Lasso** : Il s'agit d'une méthode de régularisation utilisée dans les modèles de régression pour réduire le surajustement. Elle permet de réduire le nombre de variables dans le modèle en appliquant une pénalité à la somme des **valeurs absolues** des coefficients. Cette méthode est utile pour éliminer les variables non importantes et pour améliorer la performance des modèles de régression.\n",
    "* **Ridge** : Il s'agit d'une autre méthode de régularisation utilisée dans les modèles de régression. Elle est similaire à Lasso, mais utilise une pénalité différente pour la somme des **carrés** des coefficients. Cette méthode est utile pour éviter le surajustement dans les modèles de régression."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
