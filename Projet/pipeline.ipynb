{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-traitement des données\n",
    "Voici quelques étapes à suivre pour pré-traiter les données pour une utilisation avec K-means :\n",
    "\n",
    "1. Intégration des données : Intégrez les données des différentes sources en une seule source de données. Si vous travaillez avec des données provenant de plusieurs sources, vous devez les intégrer en une seule source de données. Cela vous permettra de traiter les données comme une seule entité et de les analyser plus facilement.\n",
    "\n",
    "1. Nettoyer les données : Assurez-vous que vos données sont propres et ne contiennent pas de valeurs manquantes, de doublons ou d'autres anomalies. Si nécessaire, supprimez ou remplacez les données manquantes.\n",
    "\n",
    "2. Normaliser les données : Normalisez les données en les mettant à l'échelle de sorte que chaque variable ait une plage de valeurs comparable. La normalisation peut être effectuée en utilisant la méthode de la moyenne et de l'écart type, la méthode de la plage ou la méthode de la normalisation de l'amplitude.\n",
    "\n",
    "3. Réduire la dimensionnalité : Si vous travaillez avec des données à haute dimensionnalité, utilisez des techniques de réduction de dimensionnalité telles que l'analyse en composantes principales (PCA) pour réduire la dimensionnalité de vos données et faciliter leur analyse.\n",
    "\n",
    "4. Identifier les valeurs aberrantes : Les valeurs aberrantes peuvent fausser les résultats de K-means, il est donc important de les identifier et de les traiter correctement. Les valeurs aberrantes peuvent être supprimées ou remplacées par des valeurs plus appropriées.\n",
    "\n",
    "5. Sélectionner les caractéristiques : Si vous travaillez avec des données qui contiennent de nombreuses caractéristiques, il peut être judicieux de sélectionner les caractéristiques les plus pertinentes pour votre analyse.\n",
    "\n",
    "En résumé, le pré-traitement des données pour K-means comprend le nettoyage des données, la normalisation des données, la réduction de la dimensionnalité, l'identification et le traitement des valeurs aberrantes et la sélection des caractéristiques. En effectuant ces étapes, vous pouvez améliorer la qualité de vos données et obtenir des résultats plus significatifs à l'aide de K-means."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "La pipeline fait référence à un ensemble d'étapes ou de processus qui sont exécutés séquentiellement pour traiter les données d'entrée, extraire des caractéristiques, entraîner le modèle et prédire les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Global variables\n",
    "GENERAL_DATA_PATH = \"./data/general_data.csv\"\n",
    "EMPLOYEE_SURVEY_DATA_PATH = \"./data/employee_survey_data.csv\"\n",
    "MANAGER_SURVEY_DATA_PATH = \"./data/manager_survey_data.csv\"\n",
    "IN_TIME_DATA_PATH = \"./data/in_out_time/in_time.csv\"\n",
    "OUT_TIME_DATA_PATH = \"./data/in_out_time/out_time.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquisition des données\n",
    "Collecter des données brutes à partir de diverses sources, telles que des capteurs, des fichiers, des bases de données, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>Over18</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>PerformanceRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>40</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1661</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>Laboratory Technician</td>\n",
       "      <td>Single</td>\n",
       "      <td>25710</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>1217</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "      <td>Manufacturing Director</td>\n",
       "      <td>Married</td>\n",
       "      <td>44000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>40</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>Laboratory Technician</td>\n",
       "      <td>Single</td>\n",
       "      <td>25710</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>18</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1514</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Research Scientist</td>\n",
       "      <td>Single</td>\n",
       "      <td>38120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>33</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>572</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales Executive</td>\n",
       "      <td>Single</td>\n",
       "      <td>49360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age Attrition BusinessTravel              Department  DistanceFromHome  \\\n",
       "1660   40        No  Travel_Rarely  Research & Development                15   \n",
       "1216   27        No  Travel_Rarely                   Sales                 5   \n",
       "190    40        No  Travel_Rarely  Research & Development                15   \n",
       "1513   18        No  Travel_Rarely                   Sales                 7   \n",
       "571    33       Yes  Travel_Rarely  Research & Development                 3   \n",
       "\n",
       "      Education EducationField  EmployeeCount  EmployeeID  Gender  JobLevel  \\\n",
       "1660          3  Life Sciences              1        1661  Female         2   \n",
       "1216          4        Medical              1        1217  Female         4   \n",
       "190           3  Life Sciences              1         191  Female         2   \n",
       "1513          3  Life Sciences              1        1514    Male         1   \n",
       "571           2  Life Sciences              1         572    Male         1   \n",
       "\n",
       "                     JobRole MaritalStatus  MonthlyIncome  NumCompaniesWorked  \\\n",
       "1660   Laboratory Technician        Single          25710                 7.0   \n",
       "1216  Manufacturing Director       Married          44000                 9.0   \n",
       "190    Laboratory Technician        Single          25710                 7.0   \n",
       "1513      Research Scientist        Single          38120                 1.0   \n",
       "571          Sales Executive        Single          49360                 0.0   \n",
       "\n",
       "     Over18  PercentSalaryHike  StandardHours  StockOptionLevel  \\\n",
       "1660      Y                 14              8                 0   \n",
       "1216      Y                 17              8                 1   \n",
       "190       Y                 14              8                 0   \n",
       "1513      Y                 15              8                 0   \n",
       "571       Y                 14              8                 0   \n",
       "\n",
       "      TotalWorkingYears  TrainingTimesLastYear  YearsAtCompany  \\\n",
       "1660               22.0                      1              20   \n",
       "1216                6.0                      3               2   \n",
       "190                22.0                      1              20   \n",
       "1513                0.0                      3               0   \n",
       "571                 6.0                      2               5   \n",
       "\n",
       "      YearsSinceLastPromotion  YearsWithCurrManager  EnvironmentSatisfaction  \\\n",
       "1660                        5                    13                      2.0   \n",
       "1216                        2                     2                      1.0   \n",
       "190                         5                    13                      2.0   \n",
       "1513                        0                     0                      4.0   \n",
       "571                         0                     3                      1.0   \n",
       "\n",
       "      JobSatisfaction  WorkLifeBalance  JobInvolvement  PerformanceRating  \n",
       "1660              3.0              3.0               3                  3  \n",
       "1216              2.0              3.0               2                  3  \n",
       "190               3.0              3.0               3                  3  \n",
       "1513              3.0              3.0               3                  3  \n",
       "571               1.0              3.0               2                  3  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(data_path):\n",
    "    csv_path = os.path.join(data_path)\n",
    "    return pd.read_csv(csv_path, sep=',')\n",
    "\n",
    "def agregate_dataframes(list_df, on_column, how):\n",
    "    df_master = list_df[0]\n",
    "    for df in list_df[1:]:\n",
    "        df_master = df_master.merge(df,\n",
    "                       on = on_column, \n",
    "                       how = how)\n",
    "    return df_master\n",
    "\n",
    "# Load data\n",
    "df_general = load_data(GENERAL_DATA_PATH)\n",
    "df_employee_survey = load_data(EMPLOYEE_SURVEY_DATA_PATH)\n",
    "df_manager_survey = load_data(MANAGER_SURVEY_DATA_PATH)\n",
    "df_in_time = load_data(IN_TIME_DATA_PATH)\n",
    "df_out_time = load_data(OUT_TIME_DATA_PATH)\n",
    "# Merge dataframes\n",
    "df_total = agregate_dataframes(\n",
    "    [df_general, df_employee_survey, df_manager_survey],\n",
    "    \"EmployeeID\",\n",
    "    \"outer\"\n",
    ")\n",
    "\n",
    "# Display a sample of 5 rows\n",
    "df_total.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement des données\n",
    "Nettoyer, normaliser et préparer les données pour l'analyse ultérieure.\n",
    "\n",
    "### Nettoyage des données\n",
    "Une étude préablable a permis de déterminer quels champs n'apportaient pas d'informations utiles à la prédiction. De même pour les champs non éthiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_not_useful = [\n",
    "    \"Over18\",  # We have age\n",
    "    \"EducationField\",  # We have Education\n",
    "    \"EmployeeCount\",  # All at 1\n",
    "    \"StockOptionLevel\",  # Not relevant\n",
    "    \"EmployeeID\",  # Can be found in \"index + 1\"\n",
    "]\n",
    "fields_not_ethical = [\n",
    "    \"Gender\",\n",
    "    \"MaritalStatus\",\n",
    "]\n",
    "\n",
    "# Datframe with only useful fields\n",
    "df_useful = deepcopy(df_total)\n",
    "df_useful.drop(\n",
    "    fields_not_useful,\n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")\n",
    "# Datframe with useful and ethical fields\n",
    "df_ethical = deepcopy(df_total)\n",
    "df_ethical.drop(\n",
    "    fields_not_useful + fields_not_ethical,\n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Delete to free memory\n",
    "del df_total\n",
    "del fields_not_useful\n",
    "del fields_not_ethical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# List of columns to merge\n",
    "columns_to_merge = [\n",
    "    (\"TotalWorkingYears\", \"Age\"),\n",
    "    (\"YearsAtCompany\", \"Age\"),\n",
    "    (\"NumCompaniesWorked\", \"Age\"),\n",
    "    (\"YearsSinceLastPromotion\", \"Age\"),\n",
    "    (\"YearsWithCurrManager\", \"Age\"),\n",
    "    # (\"TotalWorkingYears\", \"YearsAtCompany\"),\n",
    "    # (\"TotalWorkingYears\", \"YearsSinceLastPromotion\"),\n",
    "    # (\"TotalWorkingYears\", \"YearsWithCurrManager\"),\n",
    "]\n",
    "column_ids_to_merge = []\n",
    "\n",
    "class ColumnsAdded(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        global column_ids_to_merge\n",
    "        self.column_ids_to_merge = column_ids_to_merge\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        new_columns = []\n",
    "        for ctm in self.column_ids_to_merge:\n",
    "            new_columns.append(X[:, ctm[0]] / X[:, ctm[1]])\n",
    "        return np.c_[X, *new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful train set shape:  (3528, 24)\n",
      "24 (18 + 5 + 1)\n",
      "      Age Attrition BusinessTravel Department  DistanceFromHome  Education  Gender  JobLevel            JobRole MaritalStatus  MonthlyIncome  NumCompaniesWorked  PercentSalaryHike  StandardHours  TotalWorkingYears  TrainingTimesLastYear  YearsAtCompany  YearsSinceLastPromotion  YearsWithCurrManager  EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance  JobInvolvement  PerformanceRating\n",
      "3465   41        No  Travel_Rarely      Sales                 1          4  Female         1  Research Director       Married          52570                 1.0                 14              8               10.0                      2              10                        0                     8                      2.0              3.0              3.0               4                  3\n",
      "Useful train set shape:  (3528, 33)\n",
      "27 (18 + 5 + 3 + 1)\n",
      "[ 0.46313993 -1.01661786  1.05517983 -0.96975703 -0.25963762 -0.67981848\n",
      " -0.34137399  0.         -0.16078586 -0.61566728  0.50881521 -0.67720831\n",
      "  1.09888164 -0.66197739  0.26391949  0.33777006  1.79798879 -0.43206495\n",
      "  0.          0.          1.          0.          0.          1.\n",
      "  0.          0.          0.          0.          0.          1.\n",
      "  0.          0.          0.        ]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (3528, 33), indices imply (3528, 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[300], line 96\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mprint\u001b[39m(useful_train_set_prepared[\u001b[39m0\u001b[39m])\n\u001b[1;32m     95\u001b[0m \u001b[39m# Convert to dataframe to name columns\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m useful_train_set_prepared_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(\n\u001b[1;32m     97\u001b[0m     useful_train_set_prepared, columns\u001b[39m=\u001b[39;49museful_num_attribs \u001b[39m+\u001b[39;49m get_named_columns() \u001b[39m+\u001b[39;49m cat_attribs\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m     99\u001b[0m ethical_train_set_prepared_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[1;32m    100\u001b[0m     ethical_train_set_prepared, columns\u001b[39m=\u001b[39methical_num_attribs \u001b[39m+\u001b[39m get_named_columns() \u001b[39m+\u001b[39m cat_attribs\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    103\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mUseful train set shape: \u001b[39m\u001b[39m\"\u001b[39m, useful_train_set_prepared_df\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/frame.py:722\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    712\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    713\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    714\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    719\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    720\u001b[0m         )\n\u001b[1;32m    721\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 722\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    723\u001b[0m             data,\n\u001b[1;32m    724\u001b[0m             index,\n\u001b[1;32m    725\u001b[0m             columns,\n\u001b[1;32m    726\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    727\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    728\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    729\u001b[0m         )\n\u001b[1;32m    731\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/internals/construction.py:349\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    345\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    346\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    347\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    353\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (3528, 33), indices imply (3528, 26)"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    \"\"\"\n",
    "    Split the data into a training set and a test set.\n",
    "    \"\"\"\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=test_ratio, random_state=42)\n",
    "    for train_index, test_index in split.split(data, data[\"Attrition\"]):\n",
    "        strat_train_set = data.loc[train_index]\n",
    "        strat_test_set = data.loc[test_index]\n",
    "    return strat_train_set, strat_test_set\n",
    "\n",
    "def get_named_columns(columns: list[tuple[str]]=columns_to_merge) -> list[str]:\n",
    "    \"\"\"\n",
    "    Return a list of columns names with the format \"column1PerColumn2\"\n",
    "    \"\"\"\n",
    "    named_columns = []\n",
    "    for ctm in columns:\n",
    "        named_columns.append(ctm[0] + \"Per\" + ctm[1])\n",
    "    return named_columns\n",
    "\n",
    "def get_columns_ids(names: list[str], columns: list[tuple[str]]=columns_to_merge) -> list[tuple[int]]:\n",
    "    \"\"\"\n",
    "    Return a list of columns ids from names (only if the column name is in \"columns\").\n",
    "    \"\"\"\n",
    "    column_ids = []\n",
    "    for c in columns:\n",
    "        tmp = tuple()\n",
    "        for i in c:\n",
    "            tmp += (names.index(i),)\n",
    "        column_ids.append(tmp)\n",
    "    return column_ids\n",
    "\n",
    "# Split train and test sets\n",
    "useful_train_set, useful_test_set = split_train_test(df_useful, 0.2)\n",
    "ethical_train_set, ethical_test_set = split_train_test(df_ethical, 0.2)\n",
    "\n",
    "# Create the pipeline for numerical attributes\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', ColumnsAdded()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# -- Useful --\n",
    "useful_train_set_num = useful_train_set.select_dtypes(include=[np.number])\n",
    "useful_num_attribs = list(useful_train_set_num)\n",
    "column_ids_to_merge = get_columns_ids(useful_num_attribs)  # ids for useful set\n",
    "useful_train_set_num_tr = num_pipeline.fit_transform(useful_train_set_num)\n",
    "# -- Ethical --\n",
    "ethical_train_set_num = ethical_train_set.select_dtypes(include=[np.number])\n",
    "ethical_num_attribs = list(ethical_train_set_num)\n",
    "column_ids_to_merge = get_columns_ids(ethical_num_attribs)  # ids for ethical set\n",
    "ethical_train_set_num_tr = num_pipeline.fit_transform(ethical_train_set_num)\n",
    "\n",
    "# List of categorical attributes\n",
    "cat_attribs = [\"BusinessTravel\", \"Department\", \"JobRole\"]\n",
    "\n",
    "useful_full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, useful_num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "ethical_full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, ethical_num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "\n",
    "print(\"Useful train set shape: \", useful_train_set.shape)\n",
    "print(\n",
    "    len(useful_num_attribs + get_named_columns()) + 1,\n",
    "    f\"({len(useful_num_attribs)} + {len(get_named_columns())} + 1)\"\n",
    ")\n",
    "# Display first line\n",
    "print(useful_train_set.head(1).to_string())\n",
    "\n",
    "column_ids_to_merge = []\n",
    "# -- Useful --\n",
    "useful_train_set_prepared = useful_full_pipeline.fit_transform(useful_train_set)\n",
    "# -- Ethical --\n",
    "ethical_train_set_prepared = ethical_full_pipeline.fit_transform(ethical_train_set)\n",
    "\n",
    "print(\"Useful train set shape: \", useful_train_set_prepared.shape)\n",
    "print(\n",
    "    len(useful_num_attribs + get_named_columns() + cat_attribs) + 1,\n",
    "    f\"({len(useful_num_attribs)} + {len(get_named_columns())} + {len(cat_attribs)} + 1)\"\n",
    ")\n",
    "# Display first line\n",
    "print(useful_train_set_prepared[0])\n",
    "\n",
    "# Convert to dataframe to name columns\n",
    "useful_train_set_prepared_df = pd.DataFrame(\n",
    "    useful_train_set_prepared, columns=useful_num_attribs + get_named_columns() + cat_attribs\n",
    ")\n",
    "ethical_train_set_prepared_df = pd.DataFrame(\n",
    "    ethical_train_set_prepared, columns=ethical_num_attribs + get_named_columns() + cat_attribs\n",
    ")\n",
    "\n",
    "print(\"Useful train set shape: \", useful_train_set_prepared_df.shape)\n",
    "\n",
    "# Delete to free memory\n",
    "del columns_to_merge\n",
    "del df_useful\n",
    "del df_ethical\n",
    "del useful_train_set\n",
    "del useful_test_set\n",
    "del ethical_train_set\n",
    "del ethical_test_set\n",
    "del useful_train_set_num\n",
    "del useful_train_set_num_tr\n",
    "del ethical_train_set_num\n",
    "del ethical_train_set_num_tr\n",
    "del useful_num_attribs\n",
    "del ethical_num_attribs\n",
    "del cat_attribs\n",
    "del useful_full_pipeline\n",
    "del ethical_full_pipeline\n",
    "del useful_train_set_prepared\n",
    "del ethical_train_set_prepared"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction de caractéristiques\n",
    "Extraire les caractéristiques pertinentes des données brutes pour les utiliser dans l'apprentissage automatique."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection des modèles\n",
    "Sélectionner le modèle d'apprentissage automatique le plus approprié pour le problème spécifique que l'on cherche à résoudre."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle\n",
    "Entraîner le modèle sélectionné sur les données d'entraînement en utilisant des algorithmes d'apprentissage automatique appropriés."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation du modèle\n",
    "Evaluer les performances du modèle sur des données de test pour mesurer sa précision, sa fiabilité et sa robustesse."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en production du modèle\n",
    "Intégrer le modèle entraîné dans une application en temps réel pour effectuer des prédictions sur de nouvelles données."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
