{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-traitement des données\n",
    "Voici quelques étapes à suivre pour pré-traiter les données pour une utilisation avec K-means :\n",
    "\n",
    "1. Intégration des données : Intégrez les données des différentes sources en une seule source de données. Si vous travaillez avec des données provenant de plusieurs sources, vous devez les intégrer en une seule source de données. Cela vous permettra de traiter les données comme une seule entité et de les analyser plus facilement.\n",
    "\n",
    "1. Nettoyer les données : Assurez-vous que vos données sont propres et ne contiennent pas de valeurs manquantes, de doublons ou d'autres anomalies. Si nécessaire, supprimez ou remplacez les données manquantes.\n",
    "\n",
    "2. Normaliser les données : Normalisez les données en les mettant à l'échelle de sorte que chaque variable ait une plage de valeurs comparable. La normalisation peut être effectuée en utilisant la méthode de la moyenne et de l'écart type, la méthode de la plage ou la méthode de la normalisation de l'amplitude.\n",
    "\n",
    "3. Réduire la dimensionnalité : Si vous travaillez avec des données à haute dimensionnalité, utilisez des techniques de réduction de dimensionnalité telles que l'analyse en composantes principales (PCA) pour réduire la dimensionnalité de vos données et faciliter leur analyse.\n",
    "\n",
    "4. Identifier les valeurs aberrantes : Les valeurs aberrantes peuvent fausser les résultats de K-means, il est donc important de les identifier et de les traiter correctement. Les valeurs aberrantes peuvent être supprimées ou remplacées par des valeurs plus appropriées.\n",
    "\n",
    "5. Sélectionner les caractéristiques : Si vous travaillez avec des données qui contiennent de nombreuses caractéristiques, il peut être judicieux de sélectionner les caractéristiques les plus pertinentes pour votre analyse.\n",
    "\n",
    "En résumé, le pré-traitement des données pour K-means comprend le nettoyage des données, la normalisation des données, la réduction de la dimensionnalité, l'identification et le traitement des valeurs aberrantes et la sélection des caractéristiques. En effectuant ces étapes, vous pouvez améliorer la qualité de vos données et obtenir des résultats plus significatifs à l'aide de K-means."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "La pipeline fait référence à un ensemble d'étapes ou de processus qui sont exécutés séquentiellement pour traiter les données d'entrée, extraire des caractéristiques, entraîner le modèle et prédire les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Global variables\n",
    "GENERAL_DATA_PATH = \"./data/general_data.csv\"\n",
    "EMPLOYEE_SURVEY_DATA_PATH = \"./data/employee_survey_data.csv\"\n",
    "MANAGER_SURVEY_DATA_PATH = \"./data/manager_survey_data.csv\"\n",
    "IN_TIME_DATA_PATH = \"./data/in_out_time/in_time.csv\"\n",
    "OUT_TIME_DATA_PATH = \"./data/in_out_time/out_time.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquisition des données\n",
    "Collecter des données brutes à partir de diverses sources, telles que des capteurs, des fichiers, des bases de données, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobRole</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>Over18</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>AvgTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Manufacturing Director</td>\n",
       "      <td>Married</td>\n",
       "      <td>25920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.089688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>37</td>\n",
       "      <td>No</td>\n",
       "      <td>Non-Travel</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>1611</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>Laboratory Technician</td>\n",
       "      <td>Married</td>\n",
       "      <td>20080</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10.736613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>39</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>1</td>\n",
       "      <td>1517</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>21050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7.603831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>29</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>3054</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>Research Director</td>\n",
       "      <td>Single</td>\n",
       "      <td>66670</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7.767983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>50</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>1</td>\n",
       "      <td>1690</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>Sales Executive</td>\n",
       "      <td>Married</td>\n",
       "      <td>29600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.773574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age Attrition     BusinessTravel              Department  \\\n",
       "14     28        No      Travel_Rarely  Research & Development   \n",
       "1610   37        No         Non-Travel  Research & Development   \n",
       "1516   39        No      Travel_Rarely                   Sales   \n",
       "3053   29        No      Travel_Rarely  Research & Development   \n",
       "1689   50        No  Travel_Frequently                   Sales   \n",
       "\n",
       "      DistanceFromHome  Education EducationField  EmployeeCount  EmployeeID  \\\n",
       "14                   1          3  Life Sciences              1          15   \n",
       "1610                 1          3        Medical              1        1611   \n",
       "1516                 5          4      Marketing              1        1517   \n",
       "3053                 1          3  Life Sciences              1        3054   \n",
       "1689                 2          2      Marketing              1        1690   \n",
       "\n",
       "      Gender  JobLevel                 JobRole MaritalStatus  MonthlyIncome  \\\n",
       "14      Male         1  Manufacturing Director       Married          25920   \n",
       "1610    Male         3   Laboratory Technician       Married          20080   \n",
       "1516  Female         2         Human Resources      Divorced          21050   \n",
       "3053  Female         2       Research Director        Single          66670   \n",
       "1689    Male         1         Sales Executive       Married          29600   \n",
       "\n",
       "      NumCompaniesWorked Over18  PercentSalaryHike  StandardHours  \\\n",
       "14                   1.0      Y                 14              8   \n",
       "1610                 3.0      Y                 22              8   \n",
       "1516                 0.0      Y                 20              8   \n",
       "3053                 9.0      Y                 12              8   \n",
       "1689                 1.0      Y                 14              8   \n",
       "\n",
       "      StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n",
       "14                   0                5.0                      2   \n",
       "1610                 0               15.0                      5   \n",
       "1516                 0               19.0                      3   \n",
       "3053                 1                6.0                      6   \n",
       "1689                 3               32.0                      2   \n",
       "\n",
       "      YearsAtCompany  YearsSinceLastPromotion  YearsWithCurrManager  \\\n",
       "14                 5                        0                     4   \n",
       "1610              13                       10                     7   \n",
       "1516              18                        3                     7   \n",
       "3053               3                        1                     2   \n",
       "1689              32                       10                     7   \n",
       "\n",
       "      EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance  \\\n",
       "14                        4.0              4.0              2.0   \n",
       "1610                      2.0              3.0              3.0   \n",
       "1516                      3.0              4.0              2.0   \n",
       "3053                      4.0              4.0              3.0   \n",
       "1689                      1.0              2.0              3.0   \n",
       "\n",
       "      JobInvolvement  PerformanceRating    AvgTime  \n",
       "14                 3                  3   6.089688  \n",
       "1610               2                  4  10.736613  \n",
       "1516               3                  4   7.603831  \n",
       "3053               4                  3   7.767983  \n",
       "1689               3                  3   6.773574  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(data_path):\n",
    "    csv_path = os.path.join(data_path)\n",
    "    return pd.read_csv(csv_path, sep=',')\n",
    "\n",
    "def agregate_dataframes(list_df, on_column, how):\n",
    "    df_master = list_df[0]\n",
    "    for df in list_df[1:]:\n",
    "        df_master = df_master.merge(df,\n",
    "                       on = on_column, \n",
    "                       how = how)\n",
    "    return df_master\n",
    "\n",
    "def avg_time(df):\n",
    "    '''\n",
    "    Calculate the average time of in_time and out_time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Dataframe with in_time or out_time.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        Dataframe with EmployeeID and AvgTime.\n",
    "    '''\n",
    "    # Set first column as index\n",
    "    df = df.copy().set_index(df.columns[0])\n",
    "    # Remove first column\n",
    "    df = df.copy().transpose()\n",
    "\n",
    "    # Convertir les valeurs datetime en valeurs time\n",
    "    df = df.apply(pd.to_datetime)\n",
    "    df = df.apply(lambda x: x - x.dt.normalize())\n",
    "    df = df.mean(skipna=True)\n",
    "    # Add column EmployeeID\n",
    "    df = df.to_frame().reset_index()\n",
    "    df.columns = [\"EmployeeID\", \"AvgTime\"]\n",
    "    return df\n",
    "\n",
    "# Load data\n",
    "df_general = load_data(GENERAL_DATA_PATH)\n",
    "df_employee_survey = load_data(EMPLOYEE_SURVEY_DATA_PATH)\n",
    "df_manager_survey = load_data(MANAGER_SURVEY_DATA_PATH)\n",
    "df_in_time = load_data(IN_TIME_DATA_PATH)\n",
    "df_out_time = load_data(OUT_TIME_DATA_PATH)\n",
    "# Merge dataframes\n",
    "df_total = agregate_dataframes(\n",
    "    [df_general, df_employee_survey, df_manager_survey],\n",
    "    \"EmployeeID\",\n",
    "    \"outer\"\n",
    ")\n",
    "\n",
    "# --- HANDLE IN AND OUT TIME ---\n",
    "# Get average in time\n",
    "avg_in_time_per_employee = avg_time(df_in_time)\n",
    "# Get average out time\n",
    "avg_out_time_per_employee = avg_time(df_out_time)\n",
    "# Merge in and out time\n",
    "avg_work_time_per_employee = avg_out_time_per_employee.copy()\n",
    "avg_work_time_per_employee[\"AvgTime\"] = avg_out_time_per_employee[\"AvgTime\"] - avg_in_time_per_employee[\"AvgTime\"]\n",
    "avg_work_time_per_employee[\"AvgTime\"] = avg_work_time_per_employee[\"AvgTime\"].apply(lambda x: x.total_seconds() / 3600)\n",
    "\n",
    "# Merge with total dataframe\n",
    "df_total = df_total.merge(\n",
    "    avg_work_time_per_employee,\n",
    "    on = \"EmployeeID\",\n",
    "    how = \"outer\"\n",
    ")\n",
    "\n",
    "# Display a random sample of 5 rows\n",
    "df_total.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nettoyer, normaliser et préparer les données pour l'analyse ultérieure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une étude préablable a permis de déterminer quels champs n'apportaient pas d'informations utiles à la prédiction. De même pour les champs non éthiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape useful: (4410, 26)\n",
      "Shape useful: (4410, 24)\n"
     ]
    }
   ],
   "source": [
    "fields_not_useful = [\n",
    "    \"Over18\",  # We have age\n",
    "    \"EducationField\",  # We have Education\n",
    "    \"EmployeeCount\",  # All at 1\n",
    "    \"StockOptionLevel\",  # Not relevant\n",
    "]\n",
    "fields_not_ethical = [\n",
    "    \"Gender\",\n",
    "    \"MaritalStatus\",\n",
    "]\n",
    "\n",
    "# Datframe with only useful fields\n",
    "df_useful = deepcopy(df_total)\n",
    "df_useful.drop(\n",
    "    fields_not_useful,\n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")\n",
    "print(\"Shape useful:\", df_useful.shape)\n",
    "\n",
    "# Datframe with useful and ethical fields\n",
    "df_ethical = deepcopy(df_total)\n",
    "df_ethical.drop(\n",
    "    fields_not_useful + fields_not_ethical,\n",
    "    axis=1,\n",
    "    inplace=True\n",
    ")\n",
    "print(\"Shape useful:\", df_ethical.shape)\n",
    "\n",
    "# Delete to free memory\n",
    "del df_total\n",
    "del fields_not_useful\n",
    "del fields_not_ethical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to merge\n",
    "columns_to_merge = [\n",
    "    (\"TotalWorkingYears\", \"Age\"),\n",
    "    (\"YearsAtCompany\", \"Age\"),\n",
    "    (\"NumCompaniesWorked\", \"Age\"),\n",
    "    (\"YearsSinceLastPromotion\", \"Age\"),\n",
    "    (\"YearsWithCurrManager\", \"Age\"),\n",
    "    (\"YearsAtCompany\", \"TotalWorkingYears\"),\n",
    "    (\"YearsSinceLastPromotion\", \"TotalWorkingYears\"),\n",
    "    (\"YearsWithCurrManager\", \"TotalWorkingYears\"),\n",
    "]\n",
    "column_ids_to_merge = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    \"\"\"\n",
    "    Split the data into a training set and a test set.\n",
    "    \"\"\"\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=test_ratio, random_state=42)\n",
    "    for train_index, test_index in split.split(data, data[\"Attrition\"]):\n",
    "        strat_train_set = data.loc[train_index]\n",
    "        strat_test_set = data.loc[test_index]\n",
    "    return strat_train_set, strat_test_set\n",
    "\n",
    "# Split train and test sets\n",
    "useful_train_set, useful_test_set = split_train_test(df_useful, 0.2)\n",
    "ethical_train_set, ethical_test_set = split_train_test(df_ethical, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful set:\n",
      "           Age  DistanceFromHome  Education  EmployeeID  JobLevel  MonthlyIncome  NumCompaniesWorked  PercentSalaryHike  StandardHours  TotalWorkingYears  TrainingTimesLastYear  YearsAtCompany  YearsSinceLastPromotion  YearsWithCurrManager  EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance  JobInvolvement  PerformanceRating   AvgTime  TotalWorkingYearsPerAge  YearsAtCompanyPerAge  NumCompaniesWorkedPerAge  YearsSinceLastPromotionPerAge  YearsWithCurrManagerPerAge  YearsAtCompanyPerTotalWorkingYears  YearsSinceLastPromotionPerTotalWorkingYears  YearsWithCurrManagerPerTotalWorkingYears  BusinessTravel  Department  JobRole  Row_31  Row_32  Row_33  Row_34  Row_35  Row_36  Row_37  Row_38  Row_39  Row_40  Row_41  Row_42\n",
      "2678 -0.966876         -0.403267    0.07810    1.072029 -0.068228      -0.874845           -0.679818           0.201623            0.0          -0.676822               0.940817       -0.154624                 0.272516             -0.304352                 1.177689        -1.547575         0.337770        0.381440          -0.432065 -0.410757                -0.707559             -0.362411                 -0.727539                      -0.005307                   -0.477805                           -0.413475                                    -0.220993                                 -0.511417             0.0         0.0      1.0     0.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0\n",
      "1128  0.353139          2.050134    1.05518   -1.262716 -0.068228       2.735740            0.119915           1.287617            0.0           0.613268              -0.615667       -0.983923                -0.677208             -1.146292                 0.257856         1.169667        -2.526780        0.381440           2.314467  2.097245                 0.427741             -0.809757                  0.128357                      -0.616267                   -1.031418                           -0.530430                                    -0.474799                                 -0.739777             0.0         1.0      0.0     0.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0\n",
      "1920  0.793143         -0.525938   -0.89898   -1.091727 -0.068228       2.260045            0.919648           1.830614            0.0           0.613268              -1.393910       -0.818063                -0.044058             -0.584999                -0.661977         0.263919        -1.094505       -1.035108           2.314467  1.930990                 0.581681             -0.642002                  1.058679                       0.023787                   -0.451443                           -0.436866                                    -0.023588                                 -0.333803             0.0         1.0      0.0     0.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0\n",
      "2942  2.333160         -0.893948    1.05518   -1.397458 -0.969757      -0.817474           -0.279952           2.102113            0.0           1.645340               0.162575       -0.154624                -0.677208             -0.023705                 0.257856        -0.641828         0.337770        0.381440           2.314467  0.460717                 2.236526              0.266668                  0.091144                      -0.616267                    0.497607                            0.218082                                    -0.474799                                  0.478146             0.0         0.0      1.0     0.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     1.0     0.0     0.0\n",
      "69   -0.856874          1.682124    1.05518    1.257989 -0.068228      -0.412063            1.319514           0.744620            0.0          -0.805831               1.719060       -0.983923                -0.677208             -1.146292                 0.257856         0.263919        -1.094505        1.797989          -0.432065  0.081437                -0.762881             -0.848200                  0.630731                      -0.616267                   -1.031418                           -0.594755                                    -0.474799                                 -0.739777             0.0         0.0      1.0     0.0     1.0     0.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_ids_to_merge=[]):\n",
    "        self.column_ids_to_merge = column_ids_to_merge\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        if len(column_ids_to_merge) == 0:\n",
    "            return X\n",
    "        new_columns = []\n",
    "        for ctm in column_ids_to_merge:\n",
    "            col_1 = X[:, ctm[0]]\n",
    "            col_2 = X[:, ctm[1]]\n",
    "            # index1 * index2\n",
    "            new_columns.append(col_1 * col_2)\n",
    "        return np.c_[X, *new_columns]\n",
    "\n",
    "def get_named_columns(columns: list[tuple[str]]=columns_to_merge) -> list[str]:\n",
    "    \"\"\"\n",
    "    Return a list of columns names with the format \"column1PerColumn2\"\n",
    "    \"\"\"\n",
    "    named_columns = []\n",
    "    for ctm in columns:\n",
    "        named_columns.append(ctm[0] + \"Per\" + ctm[1])\n",
    "    return named_columns\n",
    "\n",
    "def get_columns_ids(names: list[str], columns: list[tuple[str]]=columns_to_merge) -> list[tuple[int]]:\n",
    "    \"\"\"\n",
    "    Return a list of columns ids from names (only if the column name is in \"columns\").\n",
    "    \"\"\"\n",
    "    column_ids = []\n",
    "    for c in columns:\n",
    "        tuple_ids = tuple()\n",
    "        for index in c:\n",
    "            tuple_ids += (names.index(index),)\n",
    "        column_ids.append(tuple_ids)\n",
    "    return column_ids\n",
    "\n",
    "def fill_columns(m_list: list, nb_columns: int) -> list:\n",
    "    \"\"\"\n",
    "    Fill the list to have the same length as nb_columns.\n",
    "    \"\"\"\n",
    "    len_m_list = len(m_list)\n",
    "    if len_m_list < nb_columns:\n",
    "        for index in range(nb_columns - len_m_list):\n",
    "            name = \"Row_\" + str(len_m_list + index)\n",
    "            m_list.append(name)\n",
    "    return m_list\n",
    "\n",
    "# -- Useful --\n",
    "useful_train_set_num = useful_train_set.select_dtypes(include=[np.number])\n",
    "useful_num_attribs = list(useful_train_set_num.keys())\n",
    "column_ids_to_merge = get_columns_ids(useful_num_attribs)  # ids for useful set\n",
    "\n",
    "# Create the pipeline for numerical attributes\n",
    "num_pipeline_useful = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder(column_ids_to_merge)),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# -- Ethical And Useful --\n",
    "ethical_train_set_num = ethical_train_set.select_dtypes(include=[np.number])\n",
    "ethical_num_attribs = list(ethical_train_set_num.keys())\n",
    "column_ids_to_merge = get_columns_ids(ethical_num_attribs)  # ids for ethical set\n",
    "\n",
    "# Create the pipeline for numerical attributes\n",
    "num_pipeline_ethical = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder(column_ids_to_merge)),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# List of categorical attributes\n",
    "useful_cat_attribs = [\"BusinessTravel\", \"Department\", \"JobRole\", \"Gender\", \"MaritalStatus\",]\n",
    "ethical_cat_attribs = [\"BusinessTravel\", \"Department\", \"JobRole\"]\n",
    "\n",
    "useful_full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline_useful, useful_num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), useful_cat_attribs),\n",
    "])\n",
    "ethical_full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline_ethical, ethical_num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), ethical_cat_attribs),\n",
    "])\n",
    "\n",
    "# -- Useful --\n",
    "useful_train_set_prepared = useful_full_pipeline.fit_transform(useful_train_set)\n",
    "# -- Ethical --\n",
    "ethical_train_set_prepared = ethical_full_pipeline.fit_transform(ethical_train_set)\n",
    "\n",
    "# Convert to dataframe to name columns\n",
    "# -- Useful --\n",
    "useful_columns = useful_num_attribs + get_named_columns() + useful_cat_attribs\n",
    "useful_columns = fill_columns(useful_columns, useful_train_set_prepared.shape[1])\n",
    "useful_train_set_prepared_df = pd.DataFrame(\n",
    "    useful_train_set_prepared, columns=useful_columns\n",
    ")\n",
    "# -- Ethical --\n",
    "ethical_columns = ethical_num_attribs + get_named_columns() + ethical_cat_attribs\n",
    "ethical_columns = fill_columns(ethical_columns, ethical_train_set_prepared.shape[1])\n",
    "ethical_train_set_prepared_df = pd.DataFrame(\n",
    "    ethical_train_set_prepared, columns=ethical_columns\n",
    ")\n",
    "\n",
    "print(\"Useful set:\")\n",
    "print(ethical_train_set_prepared_df.sample(5).to_string())\n",
    "\n",
    "# Delete to free memory\n",
    "del columns_to_merge\n",
    "del df_useful\n",
    "del df_ethical\n",
    "del useful_train_set\n",
    "del useful_test_set\n",
    "del ethical_train_set\n",
    "del ethical_test_set\n",
    "del useful_train_set_num\n",
    "del ethical_train_set_num\n",
    "del useful_num_attribs\n",
    "del ethical_num_attribs\n",
    "del useful_cat_attribs\n",
    "del ethical_cat_attribs\n",
    "del useful_full_pipeline\n",
    "del ethical_full_pipeline\n",
    "del useful_train_set_prepared\n",
    "del ethical_train_set_prepared"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction de caractéristiques\n",
    "Extraire les caractéristiques pertinentes des données brutes pour les utiliser dans l'apprentissage automatique."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sélection des modèles\n",
    "Sélectionner le modèle d'apprentissage automatique le plus approprié pour le problème spécifique que l'on cherche à résoudre."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle\n",
    "Entraîner le modèle sélectionné sur les données d'entraînement en utilisant des algorithmes d'apprentissage automatique appropriés."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation du modèle\n",
    "Evaluer les performances du modèle sur des données de test pour mesurer sa précision, sa fiabilité et sa robustesse."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en production du modèle\n",
    "Intégrer le modèle entraîné dans une application en temps réel pour effectuer des prédictions sur de nouvelles données."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
